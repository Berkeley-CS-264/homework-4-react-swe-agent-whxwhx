{
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..3a462f1c4c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..4a24465b43 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -2,7 +2,6 @@ import os\n import signal\n import subprocess\n \n-from django.core.files.temp import NamedTemporaryFile\n from django.db.backends.base.client import BaseDatabaseClient\n \n \n@@ -34,38 +33,21 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = None\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Provide the password via environment to avoid creating a\n+                # temporary .pgpass file. subprocess.run is available on\n+                # Python 3.5+, which is Django's minimum supported version.\n+                env = os.environ.copy()\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\n"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 40ac1d3162..998a4db790 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -759,6 +759,20 @@ class RadioSelect(ChoiceWidget):\n     template_name = 'django/forms/widgets/radio.html'\n     option_template_name = 'django/forms/widgets/radio_option.html'\n \n+    def format_value(self, value):\n+        \"\"\"\n+        For radio widgets, don't pre-select the empty option when the widget\n+        is required. ChoiceWidget.format_value turns a None value into\n+        [''], which causes an empty (\"\") choice to be selected. For radios,\n+        that results in the blank choice being rendered as checked for new\n+        required model form fields (blank=False). Select widgets intentionally\n+        keep that behaviour, so we only change it for RadioSelect.\n+        \"\"\"\n+        if value is None and not self.allow_multiple_selected and self.is_required:\n+            return []\n+        return super().format_value(value)\n+\n+\n \n class CheckboxSelectMultiple(ChoiceWidget):\n     allow_multiple_selected = True\n"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..77ea1787e 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,13 +528,95 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n+            if not is_public_member(key):\n+                continue\n+\n+            # Handle plain functions, staticmethod, classmethod, and property.\n+            # For staticmethod/classmethod, the underlying function is in __func__.\n+            # For property, we need to create a new property with the inherited\n+            # docstring if missing.\n+            target_func = None\n+            wrapper_type = None\n+\n+            if inspect.isfunction(val):\n+                target_func = val\n+                wrapper_type = None\n+            elif isinstance(val, (staticmethod, classmethod)):\n+                # staticmethod and classmethod wrap the function in __func__\n+                target_func = val.__func__\n+                wrapper_type = type(val)\n+            elif isinstance(val, property):\n+                # property doesn't expose the function via a uniform attribute,\n+                # but fget is the getter function whose __doc__ is used as the\n+                # property's docstring. If the property's __doc__ is None,\n+                # attempt to inherit from the base.\n+                if val.__doc__ is not None:\n+                    continue\n+                # find a docstring from base classes' attribute\n                 for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n+                    super_attr = getattr(base, key, None)\n+                    if super_attr is None:\n+                        continue\n+                    # If the base attribute is a property, use its __doc__\n+                    super_doc = getattr(super_attr, '__doc__', None)\n+                    if super_doc:\n+                        # replace the property in the class dict with one that\n+                        # has the inherited docstring\n+                        dct[key] = property(fget=val.fget, fset=val.fset,\n+                                            fdel=val.fdel, doc=super_doc)\n+                        break\n+                continue\n+            else:\n+                # Not a function-like object we care about\n+                continue\n+\n+            # If we have an underlying function to inspect and its doc is None,\n+            # try to inherit from base classes.\n+            if target_func is None or getattr(target_func, '__doc__', None) is not None:\n+                continue\n+\n+            for base in cls.__mro__[1:]:\n+                super_method = getattr(base, key, None)\n+                if super_method is None:\n+                    continue\n+\n+                # Unwrap descriptors on the base to get at the function/doc.\n+                if isinstance(super_method, (staticmethod, classmethod)):\n+                    super_func = super_method.__func__\n+                elif isinstance(super_method, property):\n+                    # property docstring comes from its getter\n+                    super_func = getattr(super_method, '__doc__', None)\n+                    # if we got a docstring string, use it directly\n+                    if isinstance(super_func, str) and super_func:\n+                        # Need to set the doc on the wrapped function or recreate\n+                        # the descriptor as appropriate.\n+                        if wrapper_type is None:\n+                            target_func.__doc__ = super_func\n+                        else:\n+                            dct[key] = wrapper_type(target_func)\n+                            # ensure the wrapped function has the doc\n+                            target_func.__doc__ = super_func\n+                        break\n+                    else:\n+                        super_func = None\n+                else:\n+                    # plain function or other descriptor with __doc__\n+                    super_func = getattr(super_method, '__doc__', None)\n+\n+                if super_func:\n+                    # If super_func is a function, get its __doc__; otherwise it\n+                    # may already be a docstring.\n+                    doc = super_func.__doc__ if inspect.isfunction(super_func) else super_func\n+                    if doc:\n+                        # Apply the docstring to the target. If it was wrapped\n+                        # (staticmethod/classmethod), recreate the wrapper so\n+                        # the class attribute remains of the same descriptor type.\n+                        if wrapper_type is None:\n+                            target_func.__doc__ = doc\n+                        else:\n+                            # recreate the wrapper around the function (which\n+                            # now has its doc set)\n+                            dct[key] = wrapper_type(target_func)\n                         break\n \n         super().__init__(name, bases, dct)\n"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..2c5b8e3109 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -50,12 +50,16 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler for this middleware, if needed, but don't\n+                # overwrite the current handler until the middleware is\n+                # successfully instantiated. If the middleware raises\n+                # MiddlewareNotUsed, we must not mutate the handler for the\n+                # remaining middleware stack.\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..a8a3c902ef 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -17,6 +17,7 @@ from django.core.exceptions import ImproperlyConfigured\n from django.core.handlers.wsgi import LimitedStream\n from django.core.wsgi import get_wsgi_application\n from django.utils.module_loading import import_string\n+from django.db import connections\n \n __all__ = ('WSGIServer', 'WSGIRequestHandler')\n \n@@ -116,6 +117,16 @@ class ServerHandler(simple_server.ServerHandler):\n     def close(self):\n         self.get_stdin()._read_limited()\n         super().close()\n+        # Close any database connections opened while handling this request.\n+        # In a threaded server each request may be handled in its own thread,\n+        # so make sure connections don't remain open in worker threads which\n+        # would prevent database test teardown from completing.\n+        try:\n+            connections.close_all()\n+        except Exception:\n+            # Be defensive: don't let connection-closing failures interfere\n+            # with request shutdown.\n+            pass\n \n \n class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..d5097675ef 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -157,10 +157,22 @@ class TemplateResponseMixin:\n class TemplateView(TemplateResponseMixin, ContextMixin, View):\n     \"\"\"Render a template.\"\"\"\n     def get(self, request, *args, **kwargs):\n-        # RemovedInDjango40Warning: when the deprecation ends, replace with:\n-        #   context = self.get_context_data()\n-        context_kwargs = _wrap_url_kwargs_with_deprecation_warning(kwargs)\n-        context = self.get_context_data(**context_kwargs)\n+        # Historically, URL kwargs were passed directly into the template\n+        # context. In order to surface a deprecation warning when those\n+        # kwargs are accessed from templates, we previously wrapped the\n+        # values in SimpleLazyObject instances. However, passing those\n+        # lazy objects into get_context_data() caused surprising behaviour\n+        # when view authors used the kwargs for lookups (for example,\n+        # passing them directly to the ORM) because the lazy objects were\n+        # not valid DB parameter types.\n+        #\n+        # To maintain backwards compatibility for view authors while still\n+        # warning template authors, pass the real (non-lazy) kwargs into\n+        # get_context_data() and wrap any values that actually end up in\n+        # the returned context with a SimpleLazyObject that emits the\n+        # deprecation warning when accessed.\n+        context = self.get_context_data(**kwargs)\n+        context = _wrap_context_url_kwargs_with_deprecation_warning(context, kwargs)\n         return self.render_to_response(context)\n \n \n@@ -182,6 +194,28 @@ def _wrap_url_kwargs_with_deprecation_warning(url_kwargs):\n     return context_kwargs\n \n \n+def _wrap_context_url_kwargs_with_deprecation_warning(context, url_kwargs):\n+    \"\"\"\n+    Wrap any values in `context` that originate from `url_kwargs` with a\n+    SimpleLazyObject that emits a deprecation warning when accessed.\n+    \"\"\"\n+    if not isinstance(context, dict):\n+        return context\n+    for key, value in url_kwargs.items():\n+        if key in context:\n+            @SimpleLazyObject\n+            def access_value(key=key, value=value):\n+                warnings.warn(\n+                    'TemplateView passing URL kwargs to the context is '\n+                    'deprecated. Reference %s in your template through '\n+                    'view.kwargs instead.' % key,\n+                    RemovedInDjango40Warning, stacklevel=2,\n+                )\n+                return value\n+            context[key] = access_value\n+    return context\n+\n+\n class RedirectView(View):\n     \"\"\"Provide a redirect on any GET request.\"\"\"\n     permanent = False\n"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..85b353c5f2 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -228,15 +228,29 @@ class HashedFilesMixin:\n         ]\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n+        # We collect results per original name across passes and yield each\n+        # original filename only once with its final hashed name. Error yields\n+        # from _post_process (where hashed_name is None and processed is an\n+        # Exception) are yielded immediately so callers can react to problems.\n+        results = {}\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            # If an exception was yielded, pass it through immediately.\n+            if isinstance(hashed_name, Exception) or (hashed_name is None and isinstance(processed, Exception)):\n+                yield name, hashed_name, processed\n+                continue\n+            # Store the most recent result for this original name.\n+            results[name] = (hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                # If an exception was yielded, pass it through immediately.\n+                if isinstance(hashed_name, Exception) or (hashed_name is None and isinstance(processed, Exception)):\n+                    yield name, hashed_name, processed\n+                    continue\n+                results[name] = (hashed_name, processed)\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n@@ -245,6 +259,10 @@ class HashedFilesMixin:\n         if substitutions:\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n \n+        # Now yield each original filename once with its final hashed name.\n+        for name, (hashed_name, processed) in results.items():\n+            yield name, hashed_name, processed\n+\n         # Store the processed paths\n         self.hashed_files.update(hashed_files)\n \n"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..cf5ab11895 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,9 +173,15 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        # Sort imports by grouping plain \"import ...\" before \"from ... import ...\",\n+        # then by the package/module name (the part after \"from\" in \"from ... import ...\"\n+        # or after \"import\" in \"import ...\").\n+        def _import_key(i):\n+            parts = i.split()\n+            if parts[0] == \"import\":\n+                return (0, parts[1])\n+            return (1, parts[1])\n+        sorted_imports = sorted(imports, key=_import_key)\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/django/contrib/auth/__init__.py b/django/contrib/auth/__init__.py\nindex 155330c596..b37810ad14 100644\n--- a/django/contrib/auth/__init__.py\n+++ b/django/contrib/auth/__init__.py\n@@ -16,6 +16,30 @@ BACKEND_SESSION_KEY = \"_auth_user_backend\"\n HASH_SESSION_KEY = \"_auth_user_hash\"\n REDIRECT_FIELD_NAME = \"next\"\n \n+def _session_auth_hash_matches(session_hash, user):\n+    \"\"\"\n+    Verify a session hash against the user's session auth hash using the\n+    current SECRET_KEY and any SECRET_KEY_FALLBACKS.\n+    \"\"\"\n+    if not session_hash:\n+        return False\n+    fallbacks = getattr(settings, \"SECRET_KEY_FALLBACKS\", [])\n+    # Try current key first, then fallbacks.\n+    for secret in [settings.SECRET_KEY, *fallbacks]:\n+        try:\n+            if constant_time_compare(session_hash, user.get_session_auth_hash(secret=secret)):\n+                return True\n+        except TypeError:\n+            # If the user.get_session_auth_hash doesn't accept a secret argument,\n+            # fall back to calling it without arguments for comparison.\n+            try:\n+                if constant_time_compare(session_hash, user.get_session_auth_hash()):\n+                    return True\n+            except Exception:\n+                # Ignore and try next secret if any.\n+                pass\n+    return False\n+\n \n def load_backend(path):\n     return import_string(path)()\n@@ -106,8 +130,8 @@ def login(request, user, backend=None):\n     if SESSION_KEY in request.session:\n         if _get_user_session_key(request) != user.pk or (\n             session_auth_hash\n-            and not constant_time_compare(\n-                request.session.get(HASH_SESSION_KEY, \"\"), session_auth_hash\n+            and not _session_auth_hash_matches(\n+                request.session.get(HASH_SESSION_KEY, \"\"), user\n             )\n         ):\n             # To avoid reusing another user's session, create a new, empty\n@@ -199,9 +223,7 @@ def get_user(request):\n             # Verify the session\n             if hasattr(user, \"get_session_auth_hash\"):\n                 session_hash = request.session.get(HASH_SESSION_KEY)\n-                session_hash_verified = session_hash and constant_time_compare(\n-                    session_hash, user.get_session_auth_hash()\n-                )\n+                session_hash_verified = _session_auth_hash_matches(session_hash, user)\n                 if not session_hash_verified:\n                     request.session.flush()\n                     user = None\ndiff --git a/django/contrib/auth/base_user.py b/django/contrib/auth/base_user.py\nindex 5ee30bf59c..481045bd89 100644\n--- a/django/contrib/auth/base_user.py\n+++ b/django/contrib/auth/base_user.py\n@@ -131,17 +131,24 @@ class AbstractBaseUser(models.Model):\n         \"\"\"\n         return is_password_usable(self.password)\n \n-    def get_session_auth_hash(self):\n+    def get_session_auth_hash(self, secret=None):\n         \"\"\"\n         Return an HMAC of the password field.\n+\n+        If ``secret`` is provided, use it as the HMAC key (this allows\n+        verification against SECRET_KEY_FALLBACKS). When called without\n+        arguments it preserves the previous behavior of using\n+        settings.SECRET_KEY.\n         \"\"\"\n         key_salt = \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\"\n         return salted_hmac(\n             key_salt,\n             self.password,\n+            secret=secret,\n             algorithm=\"sha256\",\n         ).hexdigest()\n \n+\n     @classmethod\n     def get_email_field_name(cls):\n         try:\n"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..c3a5927 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -80,8 +80,12 @@ class RequestEncodingMixin(object):\n         if parameters are supplied as a dict.\n         \"\"\"\n \n-        if isinstance(data, (str, bytes)):\n+        # If it's a text string, convert to a native string. If it's bytes,\n+        # return it unchanged so binary payloads are preserved.\n+        if isinstance(data, str):\n             return to_native_string(data)\n+        elif isinstance(data, bytes):\n+            return data\n         elif hasattr(data, 'read'):\n             return data\n         elif hasattr(data, '__iter__'):\n@@ -98,6 +102,7 @@ class RequestEncodingMixin(object):\n         else:\n             return data\n \n+\n     @staticmethod\n     def _encode_files(files, data):\n         \"\"\"Build the body for a multipart/form-data request.\n"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..3b29dc56d 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,12 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # If xfail evaluation was cached as None during setup/call, it may have\n+    # been modified by markers added during the test execution. Re-evaluate\n+    # the xfail marks to pick up dynamic markers added during the call.\n+    if xfailed is None:\n+        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\ndiff --git a/test_foo.py b/test_foo.py\nnew file mode 100644\nindex 000000000..71d3ed4e5\n--- /dev/null\n+++ b/test_foo.py\n@@ -0,0 +1,6 @@\n+import pytest\n+\n+def test_xfail_test(request):\n+    mark = pytest.mark.xfail(reason=\"xfail\")\n+    request.node.add_marker(mark)\n+    assert 0\n"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..840c13d 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,7 +54,15 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n+    # Remove keys that are set to None in the session_setting.\n+    for (k, v) in list(session_setting.items()):\n+        if v is None:\n+            try:\n+                del merged_setting[k]\n+            except KeyError:\n+                pass\n+\n+    # Remove keys that are set to None in the request_setting.\n     for (k, v) in request_setting.items():\n         if v is None:\n             del merged_setting[k]\n"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..dc7244f883 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -101,12 +101,28 @@ class Command(BaseCommand):\n         aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n         for alias in sorted(aliases_to_check):\n             connection = connections[alias]\n-            if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n-                    # At least one model must be migrated to the database.\n-                    router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n-                    for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n-            )):\n+            if connection.settings_dict['ENGINE'] == 'django.db.backends.dummy':\n+                continue\n+\n+            # At least one model in an app must be migrated to the database.\n+            # Call router.allow_migrate() for each app with only that app's models\n+            # to avoid passing invalid (app_label, model) combinations to routers.\n+            any_model_migrated = False\n+            for app_label in consistency_check_labels:\n+                try:\n+                    app_config = apps.get_app_config(app_label)\n+                except LookupError:\n+                    # If the app isn't installed (shouldn't really happen here),\n+                    # skip it.\n+                    continue\n+                for model in app_config.get_models():\n+                    if router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name):\n+                        any_model_migrated = True\n+                        break\n+                if any_model_migrated:\n+                    break\n+\n+            if any_model_migrated:\n                 loader.check_consistent_history(connection)\n \n         # Before anything else, see if there's conflicting apps and drop out\n"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..273f8a76c 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -303,6 +303,22 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # Also ensure that the remainder estimator (if provided as an\n+        # estimator in the constructor) has its output configured. When\n+        # fitted, transformers_ already contains a ('remainder', estimator, ...)\n+        # tuple and was handled above; but for the unfitted state the\n+        # constructor's self.remainder may be an estimator as well.\n+        remainder_param = getattr(self, \"remainder\", None)\n+        if remainder_param not in (None, \"passthrough\", \"drop\"):\n+            _safe_set_output(remainder_param, transform=transform)\n+\n+        # If _remainder exists (set during validation/fitting), ensure we also\n+        # configure the fitted remainder estimator stored there.\n+        if getattr(self, \"_remainder\", None):\n+            rem_trans = self._remainder[1]\n+            if rem_trans not in (\"passthrough\", \"drop\"):\n+                _safe_set_output(rem_trans, transform=transform)\n+\n         return self\n \n     def get_params(self, deep=True):\n"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..0cbf2c95e 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -192,10 +192,28 @@ def _restify_py37(cls: Optional[Type]) -> str:\n     elif isinstance(cls, typing._SpecialForm):\n         return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n     elif hasattr(cls, '__qualname__'):\n-        if cls.__module__ == 'typing':\n-            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n+        # Some mocked or proxy objects may have an empty __qualname__.\n+        # Fall back to __name__ or __display_name__ to avoid producing\n+        # references like \"module.\" (trailing dot).  See issue with mocked\n+        # base classes producing \"Bases: torch.nn.\" instead of\n+        # \"torch.nn.Module\".\n+        qual = getattr(cls, '__qualname__', None) or getattr(cls, '__name__', None)\n+        if not qual:\n+            qual = getattr(cls, '__display_name__', None)\n+        # If qual includes a redundant module prefix (e.g. 'pkg.mod.Class')\n+        # and it matches cls.__module__, strip it to avoid 'pkg.mod.pkg.mod.Class'.\n+        if isinstance(qual, str) and getattr(cls, '__module__', None):\n+            mod_prefix = cls.__module__ + '.'\n+            if qual.startswith(mod_prefix):\n+                qual = qual[len(mod_prefix):]\n+        if qual:\n+            if cls.__module__ == 'typing':\n+                return ':py:class:`~%s.%s`' % (cls.__module__, qual)\n+            else:\n+                return ':py:class:`%s.%s`' % (cls.__module__, qual)\n         else:\n-            return ':py:class:`%s.%s`' % (cls.__module__, cls.__qualname__)\n+            # Last resort: repr()\n+            return repr(cls)\n     elif isinstance(cls, ForwardRef):\n         return ':py:class:`%s`' % cls.__forward_arg__\n     else:\n@@ -467,4 +485,4 @@ deprecated_alias('sphinx.util.typing',\n                  {\n                      'DirectiveOption': Callable[[str], Any],\n                  },\n-                 RemovedInSphinx60Warning)\n+                 RemovedInSphinx60Warning)\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..893c9283d 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -838,6 +838,43 @@ class ASTNumberLiteral(ASTLiteral):\n         signode.append(nodes.Text(txt, txt))\n \n \n+class ASTUserDefinedLiteral(ASTLiteral):\n+    \"\"\"\n+    Represents a user-defined literal like 42_km or \"s\"_lit.\n+    Holds the underlying literal node and the identifier suffix.\n+    \"\"\"\n+    def __init__(self, literal: ASTLiteral, suffix: \"ASTIdentifier\") -> None:\n+        self.literal = literal\n+        self.suffix = suffix\n+\n+    def _stringify(self, transform: 'StringifyTransform') -> str:\n+        return transform(self.literal) + transform(self.suffix)\n+\n+    def get_id(self, version: int) -> str:\n+        # For id generation, try to combine literal id and suffix.\n+        try:\n+            lit_id = self.literal.get_id(version)\n+        except Exception:\n+            lit_id = str(self.literal)\n+        # For version >=3 return readable form, for older versions append suffix name.\n+        if version >= 3:\n+            return str(self)\n+        else:\n+            # If literal id looks like L...E try to strip L and E\n+            if isinstance(lit_id, str) and lit_id.startswith('L') and lit_id.endswith('E'):\n+                core = lit_id[1:-1]\n+            else:\n+                core = lit_id\n+            suffix_name = getattr(self.suffix, 'name', str(self.suffix))\n+            return \"L%s%sE\" % (core, suffix_name)\n+\n+    def describe_signature(self, signode: 'TextElement', mode: str,\n+                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+        txt = str(self)\n+        signode.append(nodes.Text(txt, txt))\n+\n+\n+\n class ASTStringLiteral(ASTLiteral):\n     def __init__(self, data: str) -> None:\n         self.data = data\n@@ -4662,27 +4699,42 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume builtin suffix letters like u, l, f, etc.\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+                lit = ASTNumberLiteral(self.definition[pos:self.pos])\n+                # user-defined literal: must be immediately following (no space)\n+                if self.match(identifier_re):\n+                    ident = ASTIdentifier(self.matched_text)\n+                    return ASTUserDefinedLiteral(lit, ident)\n+                return lit\n \n         string = self._parse_string()\n         if string is not None:\n-            return ASTStringLiteral(string)\n+            lit = ASTStringLiteral(string)\n+            # user-defined literal: identifier immediately following string literal\n+            if self.match(identifier_re):\n+                ident = ASTIdentifier(self.matched_text)\n+                return ASTUserDefinedLiteral(lit, ident)\n+            return lit\n \n         # character-literal\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n             try:\n-                return ASTCharLiteral(prefix, data)\n+                lit = ASTCharLiteral(prefix, data)\n+                # user-defined literal: identifier immediately following char literal\n+                if self.match(identifier_re):\n+                    ident = ASTIdentifier(self.matched_text)\n+                    return ASTUserDefinedLiteral(lit, ident)\n+                return lit\n             except UnicodeDecodeError as e:\n                 self.fail(\"Can not handle character literal. Internal error was: %s\" % e)\n             except UnsupportedMultiCharacterCharLiteral:\n                 self.fail(\"Can not handle character literal\"\n                           \" resulting in multiple decoded characters.\")\n \n-        # TODO: user-defined lit\n         return None\n \n     def _parse_fold_or_paren_expression(self) -> ASTExpression:\n@@ -7285,4 +7337,4 @@ def setup(app: Sphinx) -> Dict[str, Any]:\n         'env_version': 2,\n         'parallel_read_safe': True,\n         'parallel_write_safe': True,\n-    }\n+    }\n\\ No newline at end of file\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..0743f9b64 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -264,7 +264,13 @@ class GoogleDocstring:\n         _name, _type, _desc = before, '', after\n \n         if parse_type:\n-            match = _google_typed_arg_regex.match(before)\n+            # Only treat the \"name(type)\" form as a typed argument when the\n+            # entire \"before\" part matches that pattern. Using match() here\n+            # allowed prefixes like \"dict(str, str) opc_meta\" to be treated\n+            # as a name with a type, which is incorrect. Require a full\n+            # match to avoid mis-parsing types that themselves contain\n+            # parentheses.\n+            match = _google_typed_arg_regex.fullmatch(before)\n             if match:\n                 _name = match.group(1).strip()\n                 _type = match.group(2)\n"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..617877048a 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -213,10 +213,28 @@ def __add__(self, other):\n         sympy.geometry.point.Point.translate\n \n         \"\"\"\n-        try:\n-            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n-        except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+        # allow adding expressions like scalar * Point (which produce a Mul)\n+        from sympy.core.mul import Mul\n+        if isinstance(other, Mul):\n+            # find a Point among the multiplicative factors\n+            point_factor = None\n+            for a in other.args:\n+                if isinstance(a, Point):\n+                    point_factor = a\n+                    break\n+            if point_factor is not None:\n+                # reconstruct the scalar as the product of the other factors\n+                scalar = Mul(*[arg for arg in other.args if arg is not point_factor])\n+                scaled = point_factor * scalar\n+                try:\n+                    s, o = Point._normalize_dimension(self, Point(scaled, evaluate=False))\n+                except TypeError:\n+                    raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+        else:\n+            try:\n+                s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+            except TypeError:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n@@ -278,6 +296,14 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+        \"\"\"Right multiplication so that scalar * Point works.\n+\n+        Delegates to __mul__ after letting __mul__ handle sympification\n+        and simplification of coordinates.\n+        \"\"\"\n+        return self.__mul__(factor)\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n"
  }
}